---
category: Linux
---

## 常用软件安装文档

整理一些开发中服务器终端环境下一些常用软件的安装流程、配置文件、脚本等。

在Linux服务器上，安装软件通常有两种方式：

1. 下载对应软件源码包，手动编译安装执行。
2. 通过一些软件包管理工具来进行安装。

源码安装的优点是比较灵活，可以自由地选择软件版本、安装位置等等；缺点是流程比较繁琐，有时可能需要进行比较多的操作。

通过软件包安装的优点是简单便捷，大多情况下一条命令即可完成；缺点是系统可能缺乏某些软件的源，难以选择软件版本等等。

centos下常用的软件包管理工具是rpm和yum，yum可以理解为rpm的加强版，可以自动下载软件包的依赖。

### Mysql

#### yum安装

```shell
#查看是否存在mysql的yum源
#注意mysql的相关软件包名字为mysql-community-*
yum list |grep mysql

#如果没有，则需要进行下载，mysql相关软件包源地址：https://repo.mysql.com/，可自由选择版本
wget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpm

#下载完成后，执行以下命令安装(不是安装mysql，可以理解为安装mysql的yum源，也就是将我们下载的rpm包进行解析，以便yum可以找到)
rpm -ivh mysql-community-release-el7-5.noarch.rpm

#执行完上述操作后再次查看mysql的yum源情况，若已存在则执行下述操作安装mysql
yum -y install mysql-server

#使用yum安装的软件会自动交由systemctl管理，因此执行下述命令即可启动mysql服务器
systemctl start mysql;

#通过查看mysql相关日志(下面命令中的地址为其默认地址)获取其初始密码
grep 'temporary password' /var/log/mysqld.log

#然后需要登录mysql进行修改密码、远程连接、新建用户接等相关操作，本质上是对mysql数据库下的user表中的相关数据进行修改
#登录,输入以下命令后再输入密码即可
mysqld -uroot -p

#新建用户(host为客户端IP，%表示任意IP)
CREATE USER 'username'@'host' IDENTIFIED BY 'password';

#修改密码
update user set password=password(“newPassword”) where user=”username”;

#远程连接(两种方式)
#第一种，需要重启或者等待一段时间
update user set host = '%' where user = 'username';

#第二种，表示任意IP的myuser用户都可凭借mypassword密码访问所有数据库的所有表，且具有所有权限
#授权命令格式: GRANT privileges ON databasename.tablename TO 'username'@'host'
#username：你将创建的用户名; host：指定该用户在哪个主机上可以登陆; password：该用户的登陆密码，密码可以为空，如果为空则该用户可以不需要密码登陆服务器
#password：该用户的登陆密码，密码可以为空，如果为空则该用户可以不需要密码登陆服务器
GRANT ALL PRIVILEGES ON *.* TO 'myuser'@'%' IDENTIFIED BY 'mypassword' WITH GRANT OPTION;
FLUSH PRIVILEGES;

```

#### Docker安装

```shell
#拉取需要的版本镜像(https://hub.docker.com/)
docker pull mysql:5.7.44
#基于镜像运行容器
docker run -p 13306:3306 --name mysql-slave1 \
-v /root/docker-mysql-slave1/log:/logs \
-v /root/docker-mysql-slave1/data:/var/lib/mysql \
-v /root/docker-mysql-slave1/conf/my.cnf:/etc/mysql/my.cnf \
-e MYSQL_ROOT_PASSWORD=lcy712YYD* \
-d mysql:5.7.44

docker run -p 13307:3306 --name mysql-slave2 \
-v /root/docker-mysql-slave2/log:/logs \
-v /root/docker-mysql-slave2/data:/var/lib/mysql \
-v /root/docker-mysql-slave2/conf/my.cnf:/etc/mysql/my.cnf \
-e MYSQL_ROOT_PASSWORD=lcy712YYD* \
-d mysql:5.7.44

#踩坑记录：在进行端口映射时刚开始写成了-p 13306:13306 与 -p 13307:13307,导致远程连接死活吗连接不上。
#这段命令的语义是将宿主机的13306端口与容器的13306端口进行映射，然而mysql的默认端口号是3306，远程连接时，
#通过13306端口进入容器无法访问到mysql进程，导致连接失败。
```

#### 主从集群搭建

1个master节点；2个slave节点；

master节点通过yum工具安装；

slave节点通过docker安装；

流程如下：

1. 安装好主从mysql服务器并完成用户、远程连接等相关配置。
2. 通过修改mysql配置文件my.cnf (mysql5.7通常位于/etc/下) 进行主从复制相关配置；主要配置如下：

```shell
#master配置
[mysqld]
## 同一局域网内注意要唯一
server-id=100
## 开启二进制日志功能，可以随便取（关键）
log-bin=mysql-bin

#slave1配置
[mysqld]
## 同一局域网内注意要唯一
server-id=101
## 开启二进制日志功能，可以随便取（关键）
log-bin=mysql-bin

#slave配置
[mysqld]
## 同一局域网内注意要唯一
server-id=102
## 开启二进制日志功能，可以随便取（关键）
log-bin=mysql-bin
```

3. 通过以下命令查看master的binlog日志文件相关信息：

```shell
#其输出的master_log_file与master_log_pos需要在下面步骤中使用到
show master status;
```

4. 在slave上执行以下命令连接master并启动slave:

 ```shell
 #master-user为slave节点访问master的身份，创建方式以及授权方式见上文
 change master to master_host='master-ip', master_user='master-user', master_password='master-user-psword', master_port=3306, master_log_file='mysql-bin.000001',master_log_pos=609, master_connect_retry=30;
 #启动从节点数据读取线程
 start slave;
 ```

### Redis

#### 源码安装

```shell
#下载源码压缩包
wget https://download.redis.io/releases/redis-6.2.5.tar.gz

#下载gcc(编译源码)
yum install gcc

#解压
tar -zxvf redis-6.2.5.tar.gz
#编译，make用于根据生成的 Makefile 进行编译，生成可执行文件
cd redis-6.2.5/
make
#安装, make install用于将编译生成的可执行文件、库文件以及其他必要的文件复制到系统中相应的目录中，以便之后可以直接从命令行或其他程序调用该软件
make install

#安装完成后可执行文件在/usr/local/bin
#将默认配置文件redis.conff复制到/etc/redis.conf以便系统管理
cp redis.conf /etc/redis.conf

#将redis服务交由systemctl控制
#在/etc/systemd/system 下新建redis.service，写入如下内容：
[Unit]
Description=Redis
After=network.target

[Service]
Type=forking
ExecStart=/usr/local/bin/redis-server /etc/redis.conf
ExecReload=/usr/local/bin/redis-server -s reload
ExecStop=/usr/local/bin/redis-server -s stop
PrivateTmp=true

[Install]
WantedBy=multi-user.target

#修改配置文件，配置密码、远程连接、启动方式等
#设置允许任意IP访问
bind 0.0.0.0
#设置密码
requirepass password
#配置后台启动
daemonize yes

#启动redis-cli
systemctl start redis
```

### ELK日志收集分析系统搭建

#### 基于Docker命令

```shell
#创建网络
docker network create elk-net

#创建ES容器(日志数据存储)
docker run -d \
	--name elk-es \
    -e "ES_JAVA_OPTS=-Xms512m -Xmx512m" \
    -e "discovery.type=single-node" \
    -v /home/yyd/elk/elasticsearch/data:/usr/share/elasticsearch/data \
    -v /home/yyd/elk/elasticsearch/plugins:/usr/share/elasticsearch/plugins \
    --privileged \
    --network elk-net \
    -p 9200:9200 \
    -p 9300:9300 \
elasticsearch:7.7.0

#创建kibana(日志数据可视化)
docker run -d \
	--name elk-kibana \
	-e ELASTICSEARCH_HOSTS=http://esIP:9200 \
	--network elk-net \
	-p 5601:5601  \
kibana:7.7.0

#创建logstash(日志数据传输)
docker run -d \
  --name elk-logstash \
  -p 5044:5044 \
  -v /home/yyd/elk/logstash/logstash.conf:/usr/share/logstash/pipeline/logstash.conf \
  --network elk-net \
logstash:7.7.0

logstash.conf
input {
  tcp {
    mode => "server"
    host => "0.0.0.0"
    port => 4560
    codec => json_lines
  }
}
output {
  elasticsearch {
    hosts => "http://esIP:9200"
    index => "project-loginfo-%{+YYYY.MM.dd}"
  }
}
```

#### 基于docker-compose

```shell
#安装docker-compose(选择合适版本)
curl -L https://github.com/docker/compose/releases/download/v2.21.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose

#创建挂载目录并授权
mkdir -p /home/middleware/elk/elasticsearch/data
mkdir -p /home/middleware/elk/elasticsearch/plugins
chmod 777 /home/middleware/elk/elasticsearch/data
mkdir -p /home/middleware/elk/kibana/config
touch /home/middleware/elk/kibana/config/kibana.yml
mkdir -p /home/middleware/elk/logstash.conf/conf.d/
touch /home/middleware/elk/logstash/conf.d/logstash.conf

#kibana.yml文件内容(主要功能为进行汉化)
# Default Kibana configuration for docker target
server.host: "0.0.0.0"
server.shutdownTimeout: "5s"
# 注意你的本地IP
elasticsearch.hosts: [ "http://本地IP:9200" ]
monitoring.ui.container.elasticsearch.enabled: true
#汉化
i18n.locale: "zh-CN"

#logstash.conf文件内容(主要功能为配置数据传输方式、索引名称等)
input {
  tcp {
    mode => "server"
    host => "0.0.0.0"
    port => 4560
    codec => json
  }
}
output {
  elasticsearch {
    hosts => "es:9200"
    index => "logstash-%{+YYYY.MM.dd}"
  }
}

#创建并编写docker-compose.yml文件
touch /home/middleware/elk/docker-compose.yml
cd /home/middleware/elk
vim docker-compose.yml

#docker-compose.yml内容如下(不同版本之间可能存在一定差异)：
version: '3.7'
services:
  elasticsearch:
    image: elasticsearch:7.17.1
    container_name: elasticsearch
    privileged: true
    user: root
    environment:
      #设置集群名称为elasticsearch
      - cluster.name=elasticsearch 
      #以单一节点模式启动
      - discovery.type=single-node 
      #设置使用jvm内存大小
      - ES_JAVA_OPTS=-Xms512m -Xmx512m 
    volumes:
      - /home/middleware/elk/elasticsearch/plugins:/usr/share/elasticsearch/plugins
      - /home/middleware/elk/elasticsearch/data:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
      - 9300:9300

  logstash:
    image: logstash:7.17.1
    container_name: logstash
    ports:
       - 4560:4560
    privileged: true
    environment:
      - TZ=Asia/Shanghai
    volumes:
      #挂载logstash的配置文件
      - /home/middleware/elk/logstash/conf.d/logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    depends_on:
      - elasticsearch 
    links:
      #可以用es这个域名访问elasticsearch服务
      - elasticsearch:es 

  kibana:
    image: kibana:7.17.1
    container_name: kibana
    ports:
        - 5601:5601
    privileged: true
    links:
      #可以用es这个域名访问elasticsearch服务
      - elasticsearch:es 
    depends_on:
      - elasticsearch 
    environment:
      #设置访问elasticsearch的地址
      - elasticsearch.hosts=http://elasticsearch:9200
    volumes:
      - /home/middleware/elk/kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml

#在docker-compose.yml文件所在目录执行以下命令创建并启动ELK的各个容器
docker-compose up -d
```



#### 项目的日志矿建logback-spring.xml:

```xml
<?xml version="1.0" encoding="UTF-8" ?>
<configuration>
    <include resource="org/springframework/boot/logging/logback/defualts.xml"/>

    <springProperty scope="context" name="APPLICATION_NAME" source="spring.application.name"/>
    <springProperty scope="context" name="logFileName" source="logging.file.name"/>
    <springProperty scope="context" name="logFilePath" source="logging.file.path"/>
    <springProperty name="LOG_STASH_HOST" scope="context" source="logstash.host" defaultValue="localhost"/>
    <springProperty name="LOG_STASH_PORT" scope="context" source="logstash.port" defaultValue="4560"/>
    <!--日志在工程中的输出位置-->
    <property name="LOG_FILE" value="${logFile}"/>
    <!-- 彩色日志依赖的渲染类 -->
    <conversionRule conversionWord="clr" converterClass="org.springframework.boot.logging.logback.ColorConverter"/>
    <conversionRule conversionWord="wex"
                    converterClass="org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter"/>
    <conversionRule conversionWord="wEx"
                    converterClass="org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter"/>
    <!--控制台的日志输出样式-->
    <property name="CONSOLE_LOG_PATTERN"
              value="${CONSOLE_LOG_PATTERN:-%clr(%d{yyyy-MM-dd HH:mm:ss.SSS}){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr(${PID:- }){magenta} %clr(---){faint} %clr([%15.15t]){faint} %clr(%-40.40logger{39}){cyan} %clr(:){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}"/>
    <!--文件的日志输出样式-->
    <property name="FILE_LOG_PATTERN"
              value="${FILE_LOG_PATTERN:-%d{${LOG_DATEFORMAT_PATTERN:-yyyy-MM-dd HH:mm:ss.SSS}} ${LOG_LEVEL_PATTERN:-%5p} ${PID:- } --- [%t] %-40.40logger{39} : %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}"/>

    <!--控制台 Appender-->
    <appender name="console" class="ch.qos.logback.core.ConsoleAppender">
        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
            <level>DEBUG</level>
        </filter>
        <encoder>
            <pattern>${CONSOLE_LOG_PATTERN}</pattern>
            <charset>utf8</charset>
        </encoder>
    </appender>

    <!--开发环境日志输出配置-->
    <springProfile name="dev">
        <!--LOGSTASH-->
        <appender name="logstash" class="net.logstash.logback.appender.LogstashTcpSocketAppender">
            <destination>${LOG_STASH_HOST}:${LOG_STASH_PORT}</destination>
            <encoder charset="UTF-8" class="net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder">
                <providers>
                    <!--自定义日志输出格式-->
                    <pattern>
                        <pattern>
                            {
                            "project": "${APPLICATION_NAME}",
                            "env" : "dev",
                            "level": "%level",
                            "service": "${APP_NAME:-}",
                            "pid": "${PID:-}",
                            "thread": "%thread",
                            "class": "%logger",
                            "message": "%message",
                            "stack_trace": "%exception{20}"
                            }
                        </pattern>
                    </pattern>
                </providers>
            </encoder>
        </appender>
        <!--文件-->
        <appender name="fileAppender" class="ch.qos.logback.core.rolling.RollingFileAppender">
            <Prudent>true</Prudent>
            <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
                <FileNamePattern>
                    ${logFilePath}/running-%d{yyyy-MM-dd}.log
                </FileNamePattern>
            </rollingPolicy>
            <layout class="ch.qos.logback.classic.PatternLayout">
                <Pattern>
                    ${FILE_LOG_PATTERN}
                </Pattern>
            </layout>
        </appender>
        <root level="INFO">
            <appender-ref ref="console"/>
            <appender-ref ref="logstash"/>
            <appender-ref ref="fileAppender"/>
        </root>
    </springProfile>

    <springProfile name="prod">
        <!--LOGSTASH-->
        <appender name="logstash" class="net.logstash.logback.appender.LogstashTcpSocketAppender">
            <destination>${LOG_STASH_HOST}:${LOG_STASH_PORT}</destination>
            <encoder charset="UTF-8" class="net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder">
                <providers>
                    <!--自定义日志输出格式-->
                    <pattern>
                        <pattern>
                            {
                            "project": "${APPLICATION_NAME}",
                            "env" : "prod",
                            "level": "%level",
                            "service": "${APP_NAME:-}",
                            "pid": "${PID:-}",
                            "thread": "%thread",
                            "class": "%logger",
                            "message": "%message",
                            "stack_trace": "%exception{20}"
                            }
                        </pattern>
                    </pattern>
                </providers>
            </encoder>
        </appender>
        <!--文件-->
        <appender name="fileAppender" class="ch.qos.logback.core.rolling.RollingFileAppender">
            <Prudent>true</Prudent>
            <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
                <FileNamePattern>
                    ${logFilePath}/running-%d{yyyy-MM-dd}.log
                </FileNamePattern>
            </rollingPolicy>
            <layout class="ch.qos.logback.classic.PatternLayout">
                <Pattern>
                    ${FILE_LOG_PATTERN}
                </Pattern>
            </layout>
        </appender>
        <root level="WARN">
            <appender-ref ref="console"/>
            <appender-ref ref="logstash"/>
            <appender-ref ref="fileAppender"/>
        </root>
    </springProfile>

</configuration>
```

#### 使用AOP采集接口访问日志

```java
@Aspect
@Slf4j
@Component
public class LogAspect {
	//切入点描述 这个是controller包的切入点
    @Pointcut("execution(public * 项目基础包路径.controller.*.*(..))")
    //签名，可以理解成这个切入点的一个名称
    public void controllerLog(){}
	
    //在切入点的方法run之前要干的
    @Before("controllerLog()") 
    public void logBeforeController(JoinPoint joinPoint) {
        //这个RequestContextHolder是Springmvc提供来获得请求的东西
        RequestAttributes requestAttributes;
        requestAttributes = RequestContextHolder.getRequestAttributes();
        HttpServletRequest request = ((ServletRequestAttributes)requestAttributes).getRequest();

        AccessRecord accessRecord = new AccessRecord();
        accessRecord.setAccessTime(DateUtil.getTime("yyyy-MM-dd hh:mm:ss"));
        accessRecord.setAccessUrl(request.getRequestURL().toString());
        accessRecord.setRequestType(request.getMethod());
        
        accessRecord.setTargetMethod(joinPoint.getSignature().getDeclaringTypeName() 
                                     + "." 
                                     +             joinPoint.getSignature().getName());
        
        accessRecord.setRequestArgs(JSON.toJSONString(joinPoint.getArgs()));
		
        //输出日志(控制台、文件、logstash)
        log.info(accessRecord.toString());
    }
}
```

