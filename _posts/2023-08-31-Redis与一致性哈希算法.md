---
category: 数据库
---

## Redis与一致性哈希算法

Redis被广泛应用于缓存数据存储，随着应用的规模不断扩大，单体的Redis无法满足庞大的缓存数据存储需求，这时就需要增加物理机，搭建Redis集群。那么这时就面临一个问题，即如何对集群中的结点进行负载均衡，用大白话讲就是确定每一个缓存数据的存储位置，将所有的缓存数据分摊到不同的结点上。一致性哈希算法是这个问题比较常见的解决方案。

### 举一个简单的例子

假设有3个Redis结点，10个数据：1、2、3、4、5、 6、 7、 8、 9、10。

如何将这10个数据分摊到3个Redis结点？

需要增加一个结点时如何处理？

某一个结点崩溃了如何处理？

### 传统哈希算法是如何做的

确定结点：hash(data) % 结点数量

```
hash(1) % 3 = 1
hash(2) % 3 = 2
hash(3) % 3 = 0
...
hash(9) % 3 = 0
hash(10) % 3 = 1

最终结果：
结点1：{1,4,7,10}
结点2：{2,5,8}
结点3(0)：{3,6,9}
```

增加一个结点。

```
最终结果：
结点1：{1，5,9}
结点2：{2,6,10}
结点3：{3,7}
结点4(0)：{4, 8}
```

减少一个结点。

```
最终结果：
结点1：{1,3,5,7，9}
结点2(0)：{2,4,6,8,10}
```

可以看到，当增加一个结点或者减少一个结点时，位置发生变动的数据非常多，并且对所有节点都造成了影响。那么在实际中，这种做法将会严重影响集群扩容或者缩容的效率，容易出现不可预料的错误：不可能保证在所有的数据迁移过程中不出现问题，因此影响的数据和结点越多，出现问题的概率也会越大。

### 一致性哈希算法是怎么做的

